{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lorto4TBC-L1"
      },
      "outputs": [],
      "source": [
        "docs = ['go india',\n",
        "\t\t'india india',\n",
        "\t\t'hip hip hurray',\n",
        "\t\t'jeetega bhai jeetega india jeetega',\n",
        "\t\t'bharat mata ki jai',\n",
        "\t\t'kohli kohli',\n",
        "\t\t'sachin sachin',\n",
        "\t\t'dhoni dhoni',\n",
        "\t\t'modi ji ki jai',\n",
        "\t\t'inquilab zindabad']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "NFi62uRsDLCz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "mV0GS2JyDR0-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5DCPBmYDUjX",
        "outputId": "de9c6c73-e6ec-4717-c376-776c2459e3cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(docs)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxgVCcXRDXmp",
        "outputId": "f7e2dc67-5f3c-4c8e-9f41-15901b32a14e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 1],\n",
              " [1, 1],\n",
              " [3, 3, 10],\n",
              " [2, 11, 2, 1, 2],\n",
              " [12, 13, 4, 5],\n",
              " [6, 6],\n",
              " [7, 7],\n",
              " [8, 8],\n",
              " [14, 15, 4, 5],\n",
              " [16, 17]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences\n",
        "sequences = pad_sequences(sequences,padding='post')\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1Aotm_ODa3Z",
        "outputId": "e425bd66-4436-4bfb-9bf8-2f711e11dc09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  1,  0,  0,  0],\n",
              "       [ 1,  1,  0,  0,  0],\n",
              "       [ 3,  3, 10,  0,  0],\n",
              "       [ 2, 11,  2,  1,  2],\n",
              "       [12, 13,  4,  5,  0],\n",
              "       [ 6,  6,  0,  0,  0],\n",
              "       [ 7,  7,  0,  0,  0],\n",
              "       [ 8,  8,  0,  0,  0],\n",
              "       [14, 15,  4,  5,  0],\n",
              "       [16, 17,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(17,output_dim=2,input_length=5))\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "WnLvgKAeDcvJ",
        "outputId": "e62583ef-a0ae-4015-ed48-1a6ded11df10"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam','accuracy')"
      ],
      "metadata": {
        "id": "GIV3mPwpFQDG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(sequences)\n",
        "print(pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QqPY0Wl5FRgs",
        "outputId": "4a0e324f-f81e-41d8-bb9c-dcacd5607d9d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node sequential_4_1/embedding_4_1/GatherV2 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-15-3f46a817c7e2>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 512, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 198, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 96, in predict_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\", line 212, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 560, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py\", line 140, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\", line 4918, in take\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 1967, in take\n\nindices[9,1] = 17 is not in [0, 17)\n\t [[{{node sequential_4_1/embedding_4_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_174]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3f46a817c7e2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_4_1/embedding_4_1/GatherV2 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-15-3f46a817c7e2>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 512, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 198, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 96, in predict_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\", line 212, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 175, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\", line 560, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\", line 901, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py\", line 140, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/ops/numpy.py\", line 4918, in take\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/numpy.py\", line 1967, in take\n\nindices[9,1] = 17 is not in [0, 17)\n\t [[{{node sequential_4_1/embedding_4_1/GatherV2}}]] [Op:__inference_one_step_on_data_distributed_174]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding, Flatten\n"
      ],
      "metadata": {
        "id": "iT2n9NNsGb-X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test) = imdb.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFX27pzSGztZ",
        "outputId": "4e6382cd-7c5e-4ef7-b22d-759fa647fee4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train,padding='post',maxlen=50)\n",
        "X_test = pad_sequences(X_test,padding='post',maxlen=50)"
      ],
      "metadata": {
        "id": "dyphjC7oG4nC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt_7qUK4G6hw",
        "outputId": "ff996dbc-f40b-4cd2-d1f4-12d4d8e415b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=32, input_length=500))  # Correct parameters\n",
        "model.add(SimpleRNN(32, return_sequences=False))  # SimpleRNN layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Xpb5uR39G937",
        "outputId": "dcc34b41-c44c-4f9f-c1f0-c54993c3d538"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ldS3Qf5sMI1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# 2. Tokenize and pad sequences for proper input to the model\n",
        "max_len = 500  # Max number of words per review (pad sequences to this length)\n",
        "X_train_pad = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "# 3. Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 50))  # Remove input_length and let Keras infer it from data\n",
        "model.add(SimpleRNN(32, return_sequences=False))  # Simple RNN layer with 32 units\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid for binary classification (positive/negative)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "# 4. Train the model\n",
        "history = model.fit(X_train_pad, y_train, epochs=5, validation_data=(X_test_pad, y_test))\n",
        "\n",
        "# 5. Model evaluation\n",
        "score = model.evaluate(X_test_pad, y_test)\n",
        "print(f'Test Loss: {score[0]}, Test Accuracy: {score[1]}')\n",
        "\n",
        "# 6. Prepare test data for prediction\n",
        "test_reviews = [\n",
        "    \"The movie was okay, not great, but not bad either.\",\n",
        "    \"Absolutely loved the movie! The acting was superb, and the plot was thrilling.\",\n",
        "    \"Worst movie ever! I regret wasting my time watching it.\",\n",
        "    \"The movie had great visuals, but the storyline was a mess.\",\n",
        "    \"Oh, what a fantastic movie! I’m so glad I spent hours watching it instead of doing something productive.\",\n",
        "    \"The characters were poorly developed, and the plot was too predictable. I wouldn’t recommend this movie.\",\n",
        "    \"I really enjoyed the movie!\",\n",
        "    \"I didn't like the movie.\",\n",
        "    \"The movie was fine, I guess. It wasn’t too bad, but not too good either.\",\n",
        "    \"It had some flaws, but I still really enjoyed the movie overall!\",\n",
        "    \"The plot was unnecessarily complicated, and the pacing was off. I found myself checking the time halfway through the film.\",\n",
        "    \"The soundtrack was amazing, the acting was top-notch, and the storyline kept me on the edge of my seat. I highly recommend this movie!\",\n",
        "    \"The movie was pretty good, though I feel like it could have been much better with a few changes.\",\n",
        "    \"The cinematography in the movie was stunning, but the plot didn’t do it justice.\",\n",
        "    \"This was the best movie I’ve ever seen in my life!\",\n",
        "    \"It wasn’t bad, but it certainly wasn’t anything to write home about.\",\n",
        "    \"This movie was a complete waste of time. I wouldn't wish it on my worst enemy.\",\n",
        "    \"The action scenes were incredible, but I didn’t love the ending.\",\n",
        "    \"Terrible movie.\",\n",
        "    \"Oh, what a surprise! A movie that's actually worth watching!\"\n",
        "]\n",
        "\n",
        "# Tokenize and pad the test reviews\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(test_reviews)  # Fit tokenizer on test reviews (or you can use the training tokenizer)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_reviews)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_len)\n",
        "\n",
        "# 7. Predict sentiment for the test reviews\n",
        "predictions = model.predict(test_padded)\n",
        "\n",
        "# 8. Output predictions based on a threshold\n",
        "threshold = 0.5  # 0.5 for binary classification\n",
        "for review, pred in zip(test_reviews, predictions):\n",
        "    sentiment = 'Positive' if pred[0] >= threshold else 'Negative'\n",
        "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlZB6YnHHPRQ",
        "outputId": "6228c946-8ad5-4be9-fba0-699780b80b30"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 153ms/step - acc: 0.6181 - loss: 0.6313 - val_acc: 0.7910 - val_loss: 0.4565\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 154ms/step - acc: 0.8347 - loss: 0.3799 - val_acc: 0.8058 - val_loss: 0.4228\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 155ms/step - acc: 0.9026 - loss: 0.2462 - val_acc: 0.8250 - val_loss: 0.4201\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 180ms/step - acc: 0.9469 - loss: 0.1502 - val_acc: 0.8020 - val_loss: 0.5260\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 155ms/step - acc: 0.9753 - loss: 0.0780 - val_acc: 0.7816 - val_loss: 0.6095\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - acc: 0.7771 - loss: 0.6232\n",
            "Test Loss: 0.6094573140144348, Test Accuracy: 0.7815999984741211\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "Review: The movie was okay, not great, but not bad either.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Absolutely loved the movie! The acting was superb, and the plot was thrilling.\n",
            "Sentiment: Negative\n",
            "\n",
            "Review: Worst movie ever! I regret wasting my time watching it.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The movie had great visuals, but the storyline was a mess.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Oh, what a fantastic movie! I’m so glad I spent hours watching it instead of doing something productive.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The characters were poorly developed, and the plot was too predictable. I wouldn’t recommend this movie.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: I really enjoyed the movie!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: I didn't like the movie.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The movie was fine, I guess. It wasn’t too bad, but not too good either.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: It had some flaws, but I still really enjoyed the movie overall!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The plot was unnecessarily complicated, and the pacing was off. I found myself checking the time halfway through the film.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The soundtrack was amazing, the acting was top-notch, and the storyline kept me on the edge of my seat. I highly recommend this movie!\n",
            "Sentiment: Negative\n",
            "\n",
            "Review: The movie was pretty good, though I feel like it could have been much better with a few changes.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The cinematography in the movie was stunning, but the plot didn’t do it justice.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: This was the best movie I’ve ever seen in my life!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: It wasn’t bad, but it certainly wasn’t anything to write home about.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: This movie was a complete waste of time. I wouldn't wish it on my worst enemy.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The action scenes were incredible, but I didn’t love the ending.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Terrible movie.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Oh, what a surprise! A movie that's actually worth watching!\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "# Example of a custom review\n",
        "new_reviews = [\"This movie was fantastic!\", \"I didn't like the movie, it was boring.\"]\n",
        "\n",
        "# Tokenizing and padding the new reviews\n",
        "tokenizer = Tokenizer(num_words=10000)  # Use the same tokenizer used for training\n",
        "tokenizer.fit_on_texts(new_reviews)  # Fit on new data\n",
        "sequences = tokenizer.texts_to_sequences(new_reviews)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=500)  # Same padding length as training data\n",
        "\n",
        "# Predict the sentiment of the new reviews\n",
        "predictions = model.predict(padded_sequences)\n",
        "predictions = (predictions > 0.5).astype(\"int32\")\n",
        "\n",
        "# Output the predictions (0 for negative, 1 for positive)\n",
        "for i, review in enumerate(new_reviews):\n",
        "    sentiment = \"Positive\" if predictions[i] == 1 else \"Negative\"\n",
        "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ak80E-NKs2S",
        "outputId": "c54a8529-7863-44e1-b0cb-7d90770ce3fa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "Review: This movie was fantastic!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: I didn't like the movie, it was boring.\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.preprocessing.text import Tokenizer\n",
        "# from keras.utils import pad_sequences\n",
        "\n",
        "# Assuming the tokenizer and model are already defined and trained\n",
        "\n",
        "# Define the test reviews\n",
        "test_reviews = [\n",
        "    \"The movie was okay, not great, but not bad either.\",\n",
        "    \"Absolutely loved the movie! The acting was superb, and the plot was thrilling.\",\n",
        "    \"Worst movie ever! I regret wasting my time watching it.\",\n",
        "    \"The movie had great visuals, but the storyline was a mess.\",\n",
        "    \"Oh, what a fantastic movie! I’m so glad I spent hours watching it instead of doing something productive.\",\n",
        "    \"The characters were poorly developed, and the plot was too predictable. I wouldn’t recommend this movie.\",\n",
        "    \"I really enjoyed the movie!\",\n",
        "    \"I didn't like the movie.\",\n",
        "    \"The movie was fine, I guess. It wasn’t too bad, but not too good either.\",\n",
        "    \"It had some flaws, but I still really enjoyed the movie overall!\",\n",
        "    \"The plot was unnecessarily complicated, and the pacing was off. I found myself checking the time halfway through the film.\",\n",
        "    \"The soundtrack was amazing, the acting was top-notch, and the storyline kept me on the edge of my seat. I highly recommend this movie!\",\n",
        "    \"The movie was pretty good, though I feel like it could have been much better with a few changes.\",\n",
        "    \"The cinematography in the movie was stunning, but the plot didn’t do it justice.\",\n",
        "    \"This was the best movie I’ve ever seen in my life!\",\n",
        "    \"It wasn’t bad, but it certainly wasn’t anything to write home about.\",\n",
        "    \"This movie was a complete waste of time. I wouldn't wish it on my worst enemy.\",\n",
        "    \"The action scenes were incredible, but I didn’t love the ending.\",\n",
        "    \"Terrible movie.\",\n",
        "    \"Oh, what a surprise! A movie that's actually worth watching!\"\n",
        "]\n",
        "\n",
        "# Tokenize and pad the test reviews\n",
        "test_sequences = tokenizer.texts_to_sequences(test_reviews)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=500)\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(test_padded)\n",
        "\n",
        "# Output predictions based on threshold\n",
        "threshold = 0.5  # Adjust this if needed\n",
        "for review, pred in zip(test_reviews, predictions):\n",
        "    sentiment = 'Positive' if pred[0] >= threshold else 'Negative'\n",
        "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LegoLEELPsv",
        "outputId": "10170fb3-e9ae-44b8-e46f-7b36eff231df"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Review: The movie was okay, not great, but not bad either.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Absolutely loved the movie! The acting was superb, and the plot was thrilling.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Worst movie ever! I regret wasting my time watching it.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The movie had great visuals, but the storyline was a mess.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Oh, what a fantastic movie! I’m so glad I spent hours watching it instead of doing something productive.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The characters were poorly developed, and the plot was too predictable. I wouldn’t recommend this movie.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: I really enjoyed the movie!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: I didn't like the movie.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The movie was fine, I guess. It wasn’t too bad, but not too good either.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: It had some flaws, but I still really enjoyed the movie overall!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The plot was unnecessarily complicated, and the pacing was off. I found myself checking the time halfway through the film.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The soundtrack was amazing, the acting was top-notch, and the storyline kept me on the edge of my seat. I highly recommend this movie!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The movie was pretty good, though I feel like it could have been much better with a few changes.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The cinematography in the movie was stunning, but the plot didn’t do it justice.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: This was the best movie I’ve ever seen in my life!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: It wasn’t bad, but it certainly wasn’t anything to write home about.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: This movie was a complete waste of time. I wouldn't wish it on my worst enemy.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: The action scenes were incredible, but I didn’t love the ending.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Terrible movie.\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: Oh, what a surprise! A movie that's actually worth watching!\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ]
    }
  ]
}